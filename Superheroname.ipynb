{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'git' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/am1tyadav/superhero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('supername.txt','r') as f:\n",
    "  data = f.read()\n",
    "\n",
    "  data[:100] \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.8.0\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils import np_utils\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tf.keras.preprocessing.text.Tokenizer(\n",
    "    filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~',\n",
    "    split='\\n',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.fit_on_texts(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: '\\t', 2: 'a', 3: 'e', 4: 'r', 5: 'o', 6: 'n', 7: 'i', 8: ' ', 9: 't', 10: 's', 11: 'l', 12: 'm', 13: 'h', 14: 'd', 15: 'c', 16: 'u', 17: 'g', 18: 'k', 19: 'b', 20: 'p', 21: 'y', 22: 'w', 23: 'f', 24: 'v', 25: 'j', 26: 'z', 27: 'x', 28: 'q'}\n"
     ]
    }
   ],
   "source": [
    "char_to_index = tokenizer.word_index\n",
    "index_to_char = dict((v,k) for k,v in char_to_index.items())\n",
    "\n",
    "print(index_to_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['jumpa\\t',\n",
       " 'doctor fate\\t',\n",
       " 'starlight\\t',\n",
       " 'isildur\\t',\n",
       " 'lasher\\t',\n",
       " 'varvara\\t',\n",
       " 'the target\\t',\n",
       " 'axel\\t',\n",
       " 'battra\\t',\n",
       " 'changeling\\t']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "names = data.splitlines()\n",
    "names[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[25], [16], [12], [20], [2], [1]]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.texts_to_sequences(names[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def name_to_seq(name):\n",
    "  return [tokenizer.texts_to_sequences(c)[0][0] for c in name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[25, 16, 12, 20, 2, 1]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name_to_seq(names[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seq_to_name(seq):\n",
    "  return ''.join([index_to_char[i] for i in seq if i!= 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'jumpa\\t'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_to_name(name_to_seq(names[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[25, 16],\n",
       " [25, 16, 12],\n",
       " [25, 16, 12, 20],\n",
       " [25, 16, 12, 20, 2],\n",
       " [25, 16, 12, 20, 2, 1],\n",
       " [14, 5],\n",
       " [14, 5, 15],\n",
       " [14, 5, 15, 9],\n",
       " [14, 5, 15, 9, 5],\n",
       " [14, 5, 15, 9, 5, 4]]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences = []\n",
    "\n",
    "for name in names:\n",
    "  seq = name_to_seq(name)\n",
    "  if len(seq) >= 2:\n",
    "    sequences += [seq[:i] for i in range(2,len(seq) + 1)]\n",
    "\n",
    "sequences[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33\n"
     ]
    }
   ],
   "source": [
    "max_len = max([len(x) for x in sequences])\n",
    "print(max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0 25 16]\n"
     ]
    }
   ],
   "source": [
    "padded_sequences = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "    sequences, padding = 'pre',\n",
    "    maxlen = max_len\n",
    ")\n",
    "print(padded_sequences[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(88279, 33)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_sequences.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(88279, 32) (88279,)\n"
     ]
    }
   ],
   "source": [
    "x,y = padded_sequences[:,:-1], padded_sequences[:, -1]\n",
    "print(x.shape,y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(66209, 32) (66209,)\n",
      "(22070, 32) (22070,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test,y_train,y_test = train_test_split(x,y)\n",
    "\n",
    "print(x_train.shape,y_train.shape)\n",
    "print(x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29\n"
     ]
    }
   ],
   "source": [
    "num_chars = len(char_to_index.keys()) + 1\n",
    "print(num_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 32, 8)             232       \n",
      "                                                                 \n",
      " conv1d (Conv1D)             (None, 32, 64)            2624      \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1D  (None, 16, 64)           0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 32)                12416     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 29)                957       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 16,229\n",
      "Trainable params: 16,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding,Conv1D,MaxPool1D,LSTM\n",
    "from tensorflow.keras.layers import Bidirectional, Dense \n",
    "\n",
    "model = Sequential([\n",
    "        Embedding(num_chars,8 , input_length=max_len - 1) ,\n",
    "        Conv1D(64,5,strides=1,activation ='tanh',padding = 'causal'),\n",
    "        MaxPool1D(2),\n",
    "        LSTM(32),\n",
    "        Dense(num_chars,activation = 'softmax')            \n",
    "                     ])\n",
    "\n",
    "model.compile(\n",
    "    loss = 'sparse_ctegorical_crossentropy',\n",
    "    optimizer = 'Adam',\n",
    "    metrics = ['accuracy']\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"C:\\Users\\HANISH RAWAL\\Python1\\lib\\site-packages\\keras\\engine\\training.py\", line 1021, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\HANISH RAWAL\\Python1\\lib\\site-packages\\keras\\engine\\training.py\", line 1010, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\HANISH RAWAL\\Python1\\lib\\site-packages\\keras\\engine\\training.py\", line 1000, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\HANISH RAWAL\\Python1\\lib\\site-packages\\keras\\engine\\training.py\", line 860, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"C:\\Users\\HANISH RAWAL\\Python1\\lib\\site-packages\\keras\\engine\\training.py\", line 918, in compute_loss\n        return self.compiled_loss(\n    File \"C:\\Users\\HANISH RAWAL\\Python1\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 184, in __call__\n        self.build(y_pred)\n    File \"C:\\Users\\HANISH RAWAL\\Python1\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 133, in build\n        self._losses = tf.nest.map_structure(self._get_loss_object, self._losses)\n    File \"C:\\Users\\HANISH RAWAL\\Python1\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 272, in _get_loss_object\n        loss = losses_mod.get(loss)\n    File \"C:\\Users\\HANISH RAWAL\\Python1\\lib\\site-packages\\keras\\losses.py\", line 2369, in get\n        return deserialize(identifier)\n    File \"C:\\Users\\HANISH RAWAL\\Python1\\lib\\site-packages\\keras\\losses.py\", line 2324, in deserialize\n        return deserialize_keras_object(\n    File \"C:\\Users\\HANISH RAWAL\\Python1\\lib\\site-packages\\keras\\utils\\generic_utils.py\", line 709, in deserialize_keras_object\n        raise ValueError(\n\n    ValueError: Unknown loss function: sparse_ctegorical_crossentropy. Please ensure this object is passed to the `custom_objects` argument. See https://www.tensorflow.org/guide/keras/save_and_serialize#registering_the_custom_object for details.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\HANISH RAWAL\\Python1\\VS.cOde\\Computer vision\\Tensorflow\\Superheroname.ipynb Cell 21'\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/HANISH%20RAWAL/Python1/VS.cOde/Computer%20vision/Tensorflow/Superheroname.ipynb#ch0000021?line=0'>1</a>\u001b[0m h\u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/HANISH%20RAWAL/Python1/VS.cOde/Computer%20vision/Tensorflow/Superheroname.ipynb#ch0000021?line=1'>2</a>\u001b[0m     x_train,y_train,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/HANISH%20RAWAL/Python1/VS.cOde/Computer%20vision/Tensorflow/Superheroname.ipynb#ch0000021?line=2'>3</a>\u001b[0m     validation_data\u001b[39m=\u001b[39;49m(x_test,y_test),\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/HANISH%20RAWAL/Python1/VS.cOde/Computer%20vision/Tensorflow/Superheroname.ipynb#ch0000021?line=3'>4</a>\u001b[0m     epochs\u001b[39m=\u001b[39;49m\u001b[39m50\u001b[39;49m, verbose\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/HANISH%20RAWAL/Python1/VS.cOde/Computer%20vision/Tensorflow/Superheroname.ipynb#ch0000021?line=4'>5</a>\u001b[0m     callbacks\u001b[39m=\u001b[39;49m[\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/HANISH%20RAWAL/Python1/VS.cOde/Computer%20vision/Tensorflow/Superheroname.ipynb#ch0000021?line=5'>6</a>\u001b[0m                tf\u001b[39m.\u001b[39;49mkeras\u001b[39m.\u001b[39;49mcallbacks\u001b[39m.\u001b[39;49mEarlyStopping(monitor\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mval_accuracy\u001b[39;49m\u001b[39m'\u001b[39;49m,patience\u001b[39m=\u001b[39;49m\u001b[39m3\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/HANISH%20RAWAL/Python1/VS.cOde/Computer%20vision/Tensorflow/Superheroname.ipynb#ch0000021?line=6'>7</a>\u001b[0m     ]\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/HANISH%20RAWAL/Python1/VS.cOde/Computer%20vision/Tensorflow/Superheroname.ipynb#ch0000021?line=7'>8</a>\u001b[0m )\n",
      "File \u001b[1;32m~\\Python1\\lib\\site-packages\\keras\\utils\\traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Users/HANISH%20RAWAL/Python1/lib/site-packages/keras/utils/traceback_utils.py?line=64'>65</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     <a href='file:///c%3A/Users/HANISH%20RAWAL/Python1/lib/site-packages/keras/utils/traceback_utils.py?line=65'>66</a>\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m---> <a href='file:///c%3A/Users/HANISH%20RAWAL/Python1/lib/site-packages/keras/utils/traceback_utils.py?line=66'>67</a>\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m     <a href='file:///c%3A/Users/HANISH%20RAWAL/Python1/lib/site-packages/keras/utils/traceback_utils.py?line=67'>68</a>\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     <a href='file:///c%3A/Users/HANISH%20RAWAL/Python1/lib/site-packages/keras/utils/traceback_utils.py?line=68'>69</a>\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\Python1\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:1147\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func.<locals>.autograph_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/HANISH%20RAWAL/Python1/lib/site-packages/tensorflow/python/framework/func_graph.py?line=1144'>1145</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint:disable=broad-except\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/HANISH%20RAWAL/Python1/lib/site-packages/tensorflow/python/framework/func_graph.py?line=1145'>1146</a>\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m\"\u001b[39m\u001b[39mag_error_metadata\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m-> <a href='file:///c%3A/Users/HANISH%20RAWAL/Python1/lib/site-packages/tensorflow/python/framework/func_graph.py?line=1146'>1147</a>\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mag_error_metadata\u001b[39m.\u001b[39mto_exception(e)\n\u001b[0;32m   <a href='file:///c%3A/Users/HANISH%20RAWAL/Python1/lib/site-packages/tensorflow/python/framework/func_graph.py?line=1147'>1148</a>\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   <a href='file:///c%3A/Users/HANISH%20RAWAL/Python1/lib/site-packages/tensorflow/python/framework/func_graph.py?line=1148'>1149</a>\u001b[0m     \u001b[39mraise\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"C:\\Users\\HANISH RAWAL\\Python1\\lib\\site-packages\\keras\\engine\\training.py\", line 1021, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\HANISH RAWAL\\Python1\\lib\\site-packages\\keras\\engine\\training.py\", line 1010, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\HANISH RAWAL\\Python1\\lib\\site-packages\\keras\\engine\\training.py\", line 1000, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\HANISH RAWAL\\Python1\\lib\\site-packages\\keras\\engine\\training.py\", line 860, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"C:\\Users\\HANISH RAWAL\\Python1\\lib\\site-packages\\keras\\engine\\training.py\", line 918, in compute_loss\n        return self.compiled_loss(\n    File \"C:\\Users\\HANISH RAWAL\\Python1\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 184, in __call__\n        self.build(y_pred)\n    File \"C:\\Users\\HANISH RAWAL\\Python1\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 133, in build\n        self._losses = tf.nest.map_structure(self._get_loss_object, self._losses)\n    File \"C:\\Users\\HANISH RAWAL\\Python1\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 272, in _get_loss_object\n        loss = losses_mod.get(loss)\n    File \"C:\\Users\\HANISH RAWAL\\Python1\\lib\\site-packages\\keras\\losses.py\", line 2369, in get\n        return deserialize(identifier)\n    File \"C:\\Users\\HANISH RAWAL\\Python1\\lib\\site-packages\\keras\\losses.py\", line 2324, in deserialize\n        return deserialize_keras_object(\n    File \"C:\\Users\\HANISH RAWAL\\Python1\\lib\\site-packages\\keras\\utils\\generic_utils.py\", line 709, in deserialize_keras_object\n        raise ValueError(\n\n    ValueError: Unknown loss function: sparse_ctegorical_crossentropy. Please ensure this object is passed to the `custom_objects` argument. See https://www.tensorflow.org/guide/keras/save_and_serialize#registering_the_custom_object for details.\n"
     ]
    }
   ],
   "source": [
    "h= model.fit(\n",
    "    x_train,y_train,\n",
    "    validation_data=(x_test,y_test),\n",
    "    epochs=50, verbose=2,\n",
    "    callbacks=[\n",
    "               tf.keras.callbacks.EarlyStopping(monitor='val_accuracy',patience=3)\n",
    "    ]\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "292297d5f1f836245304c78fa03ec57e8e4aedfb70ce89be415e0fc68df92053"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
